# -*- coding: utf-8 -*-
"""cyber threats.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/15kMYPobCMFJnYvtuSPyjBpyv0mqmAlr3
"""

# Install if necessary (uncomment the next lines)
# !pip install scikit-learn
# !pip install matplotlib seaborn

# Data handling
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Preprocessing & modeling
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from sklearn.model_selection import train_test_split
from sklearn.ensemble import IsolationForest
from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay

from google.colab import files
uploaded = files.upload()

# Load CSV
df = pd.read_csv("network_traffic_dataset.csv")

# Check data structure
df.head()

# Basic info
df.info()

# Check for missing values
print(df.isnull().sum())

# Label distribution
print(df['Label'].value_counts())

label_enc = LabelEncoder()
df['Protocol'] = label_enc.fit_transform(df['Protocol'])
df['Flag'] = label_enc.fit_transform(df['Flag'])
df['Label'] = label_enc.fit_transform(df['Label'])  # Normal=0, Anomaly=1

scaler = MinMaxScaler()
scaled_cols = ['Duration', 'Src_Port', 'Dst_Port', 'Packet_Size']
df[scaled_cols] = scaler.fit_transform(df[scaled_cols])

# Correlation Heatmap
plt.figure(figsize=(10,7))
sns.heatmap(df.corr(), annot=True, cmap='coolwarm')
plt.show()

# Class Distribution
sns.countplot(x='Label', data=df)
plt.title("Normal vs Anomaly Count")
plt.show()

X = df.drop('Label', axis=1)
y = df['Label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

model = IsolationForest(contamination=0.15, random_state=42)
model.fit(X_train)

# Predict anomalies
y_pred_train = model.predict(X_train)
y_pred_test = model.predict(X_test)

# Map -1 (anomaly) to 1, 1 (normal) to 0
y_pred_train = np.where(y_pred_train == -1, 1, 0)
y_pred_test = np.where(y_pred_test == -1, 1, 0)

# Training set performance
print("Train Set:")
print(classification_report(y_train, y_pred_train))

# Test set performance
print("Test Set:")
print(classification_report(y_test, y_pred_test))

# Confusion Matrix for test set
cm = confusion_matrix(y_test, y_pred_test)
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot(cmap='Blues')
plt.show()

print(f"Anomalies detected in test set: {sum(y_pred_test)} out of {len(y_pred_test)} samples")